{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Clone Experiment: data processing 2\n",
    "This model has two layers, max pooling and a dropout. We are still using one lap of data, where driver tries to stay in the middle of the road. Now we are doing data processing and augmentation:\n",
    "* normalizing the data and mean centering\n",
    "* data augmentation by flipping the image and steering measurements\n",
    "* images are cropped\n",
    "* images are seen from multiple camera angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "lines = []\n",
    "with open('../../../../data/bc_one_lap/driving_log.csv') as csvfile:\n",
    "    rd = csv.reader(csvfile)\n",
    "    for line in rd:\n",
    "        lines.append(line)\n",
    "        \n",
    "        \n",
    "images = []\n",
    "measurements = []\n",
    "# update path \n",
    "for line in lines:\n",
    "    current_path = '../../../../data/bc_one_lap/IMG/' \n",
    "    # images\n",
    "    img_center = cv2.imread(current_path + line[0].split('/')[-1])\n",
    "    img_left = cv2.imread(current_path + line[1].split('/')[-1])\n",
    "    img_right = cv2.imread(current_path + line[2].split('/')[-1])\n",
    "    images.extend([img_center, img_left, img_right, cv2.flip(img_center, 1), cv2.flip(img_left, 1),\n",
    "                   cv2.flip(img_right, 1)])\n",
    "    \n",
    "    # measurements\n",
    "    steer_center = float(line[3])\n",
    "    correction = 0.2 # parameter to tune\n",
    "    steer_left = steer_center + correction\n",
    "    steer_right = steer_center - correction\n",
    "    measurements.extend([steer_center, steer_left, steer_right, steer_center*-1.0, steer_left*-1.0,\n",
    "                         steer_right*-1.0])\n",
    "    \n",
    "# now convert to numpy arrays for keras\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_2 (Lambda)                (None, 160, 320, 3)   0           lambda_input_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)        (None, 65, 320, 3)    0           lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 63, 318, 32)   896         cropping2d_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 31, 159, 32)   0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 29, 157, 64)   18496       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 29, 157, 64)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 291392)        0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             291393      flatten_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 310,785\n",
      "Trainable params: 310,785\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Convolution2D, Dropout, MaxPooling2D, Lambda, Cropping2D\n",
    "input_shape=(160,320,3)\n",
    "\n",
    "# most NN model with 2 layers and dropout\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "model.add(Convolution2D(32,3,3,activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Convolution2D(64,3,3,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7132 samples, validate on 1784 samples\n",
      "Epoch 1/3\n",
      "7132/7132 [==============================] - 206s - loss: 0.0742 - val_loss: 0.0173\n",
      "Epoch 2/3\n",
      "7132/7132 [==============================] - 173s - loss: 0.0253 - val_loss: 0.0165\n",
      "Epoch 3/3\n",
      "7132/7132 [==============================] - 179s - loss: 0.0238 - val_loss: 0.0181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcda28c7f28>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2,\n",
    "          shuffle=True, nb_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('../model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "When I used this trained model the results were the best so far. The car stayed in the middle of the road, so having 3 points of view instead of one stopped the previous tendency of being always to the right of the road. The car made it to the end of the bridge, but didn't make a full lap. Other issues were:\n",
    "* At the bridge the car hits the guardrail on the left side.\n",
    "* In one turn, near the water, the car gets very close to the edge.\n",
    "\n",
    "This can be seen in the video below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"320\" height=\"240\" controls>\n",
       "  <source src=\"basic_data2.mp4\" type=\"video/mp4\">\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"basic_data2.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
