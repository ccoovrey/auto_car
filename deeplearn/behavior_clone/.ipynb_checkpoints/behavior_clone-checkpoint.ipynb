{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Clone Model: Final\n",
    "Training data consists of the following:\n",
    "* 2 laps of center lane driving\n",
    "* 1 lap recovery from side driving\n",
    "* 1 lap of smooth curve driving\n",
    "* reverse direction: 2 laps of center lane driving\n",
    "* reverse direction: 1 lap recovery from side driving\n",
    "* reverse direction: 1 lap of smooth curve driving\n",
    "\n",
    "Training data undergoes data processing and augmentation:\n",
    "* normalizing the data and mean centering\n",
    "* data augmentation by flipping the image and steering measurements\n",
    "* images are cropped\n",
    "* images are seen from multiple camera angles\n",
    "\n",
    "The model is based on nvidia model. This model has the following 5 convolutional layers:\n",
    "* convolutional layer 1: 24 5x5 filters with 2x2 stride\n",
    "* convolutional layer 2: 36 5x5 filters with 2x2 stride\n",
    "* convolutional layer 3: 48 5x5 filters with 2x2 stride\n",
    "* convolutional layer 4: 64 3x3 filters with single stride\n",
    "* convolutional layer 5: 64 3x3 filters with single stride with dropout\n",
    "* fully connected layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "samples = []\n",
    "with open('../../../data/bc_many/driving_log.csv') as csvfile:\n",
    "    rd = csv.reader(csvfile)\n",
    "    for line in rd:\n",
    "        samples.append(line)\n",
    "        \n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "curr_pth = '../../../data/bc_many/IMG/'\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            measurements = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                # images\n",
    "                img_center = cv2.imread(curr_pth + batch_sample[0].split('/')[-1])\n",
    "                img_left = cv2.imread(curr_pth + batch_sample[1].split('/')[-1])\n",
    "                img_right = cv2.imread(curr_pth + batch_sample[2].split('/')[-1])\n",
    "                images.extend([img_center, img_left, img_right, cv2.flip(img_center, 1), cv2.flip(img_left, 1),\n",
    "                               cv2.flip(img_right, 1)])\n",
    "                \n",
    "                # measurements\n",
    "                steer_center = float(batch_sample[3])\n",
    "                correction = 0.2 # parameter to tune\n",
    "                steer_left = steer_center + correction\n",
    "                steer_right = steer_center - correction\n",
    "                measurements.extend([steer_center, steer_left, steer_right, steer_center*-1.0, steer_left*-1.0,\n",
    "                                     steer_right*-1.0])\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            #yild sklearn.utils.shuffle(X_train, y_train)\n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 160, 320, 3)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)        (None, 65, 320, 3)    0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 31, 158, 24)   1824        cropping2d_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 77, 36)    21636       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 5, 37, 48)     43248       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 35, 64)     27712       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 33, 64)     36928       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1, 33, 64)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 2112)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 250)           528250      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             251         dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 659,849\n",
      "Trainable params: 659,849\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Convolution2D, Dropout, MaxPooling2D, Lambda, Cropping2D\n",
    "input_shape=(160,320,3)\n",
    "\n",
    "# most NN model with 2 layers and dropout\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "model.add(Convolution2D(24,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Convolution2D(64,3,3,activation='relu'))\n",
    "model.add(Convolution2D(64,3,3,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8064/8194 [============================>.] - ETA: 1s - loss: 0.0581"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uber/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8256/8194 [==============================] - 78s - loss: 0.0580 - val_loss: 0.0507\n",
      "Epoch 2/3\n",
      "8256/8194 [==============================] - 77s - loss: 0.0484 - val_loss: 0.0422\n",
      "Epoch 3/3\n",
      "8256/8194 [==============================] - 79s - loss: 0.0433 - val_loss: 0.0332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f637f5a5898>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit_generator(train_generator, samples_per_epoch= \\\n",
    "                    len(train_samples), validation_data=validation_generator, \\\n",
    "                    nb_val_samples=len(validation_samples), nb_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "The final model used an NVIDIA type model with seven times more training data than earlier learning models (one lap).\n",
    "The car drove very smoothly down the simulated track one straight and around curves. There were two instances that the\n",
    "car went on the left yellow lines, but the car smoothly recovered. \n",
    "\n",
    "This can be seen in the video below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"320\" height=\"240\" controls>\n",
       "  <source src=\"final_model.mp4\" type=\"video/mp4\">\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"final_model.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
